{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyObm9WxVN+USqC6T3bGMKqd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ZO2L8CqS5jTS"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Projeto: Classificação de Incêndios Florestais\n","Autor: Alysson Patricio\n","\n","Versão adaptada a partir de um desafio prático da Fábrica de Software - UNIPÊ.\n","Objetivo: Construir e avaliar modelos de Machine Learning para prever o nível de alerta\n","com base em variáveis categóricas e numéricas.\n","\"\"\"\n","\n","# ================================\n","# 1. Importando bibliotecas\n","# ================================\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import joblib\n","\n","# ================================\n","# 2. Carregando os dados\n","# ================================\n","dados = pd.read_csv(\"/content/Forest Fires.csv\")\n","\n","print(\"Amostra inicial da base:\")\n","print(dados.head())\n","\n","print(\"\\nResumo da estrutura do DataFrame:\")\n","dados.info()\n","\n","# ================================\n","# 3. Tratamento de dados\n","# ================================\n","# Padronizando a coluna de alertas\n","dados['alertlevel'] = dados['alertlevel'].str.upper()\n","\n","# Removendo categorias indesejadas\n","dados = dados[dados['alertlevel'] != 'ORANGE']\n","\n","# Criando variável binária baseada na severidade\n","limiar_severidade = dados['severity'].median()\n","dados['nivel_alerta'] = dados['severity'].apply(\n","    lambda valor: 'ALTO' if valor > limiar_severidade else 'BAIXO'\n",")\n","\n","print(f\"\\nMediana usada como limiar: {limiar_severidade}\")\n","print(\"Distribuição da variável alvo binária:\")\n","print(dados['nivel_alerta'].value_counts())\n","\n","# ================================\n","# 4. Seleção de features\n","# ================================\n","atributos = ['country', 'severity', 'Duration (days)']\n","alvo = 'nivel_alerta'\n","base_modelo = dados[atributos + [alvo]]\n","\n","X_dados = base_modelo.drop(columns=[alvo]).values\n","y_dados = base_modelo[alvo].values\n","\n","print(\"\\nDimensões:\")\n","print(\"X_dados:\", X_dados.shape)\n","print(\"y_dados:\", y_dados.shape)\n","\n","# ================================\n","# 5. Pré-processamento\n","# ================================\n","# Codificação + escalonamento\n","indice_categorico = 0  # coluna \"country\"\n","\n","transformador_cat = ColumnTransformer(\n","    transformers=[('OneHot', OneHotEncoder(handle_unknown='ignore'), [indice_categorico])],\n","    remainder='passthrough'\n",")\n","\n","pipeline = Pipeline(steps=[\n","    ('Codificação', transformador_cat),\n","    ('Normalização', StandardScaler(with_mean=False))\n","])\n","\n","X_tratado = pipeline.fit_transform(X_dados)\n","\n","# Codificação do alvo\n","encoder_alvo = LabelEncoder()\n","y_tratado = encoder_alvo.fit_transform(y_dados)\n","nomes_classes = encoder_alvo.classes_\n","\n","print(\"\\nDimensões após pré-processamento:\")\n","print(\"X_tratado:\", X_tratado.shape)\n","print(\"Classes do alvo:\", nomes_classes)\n","\n","# ================================\n","# 6. Divisão treino/teste\n","# ================================\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_tratado, y_tratado, test_size=0.2, random_state=42\n",")\n","\n","print(\"\\nDimensões dos conjuntos:\")\n","print(\"Treino:\", X_train.shape)\n","print(\"Teste:\", X_test.shape)\n","\n","# ================================\n","# 7. Treinamento de modelos\n","# ================================\n","modelo_logistico = LogisticRegression(max_iter=1000)\n","modelo_logistico.fit(X_train, y_train)\n","print(\"Modelo Regressão Logística treinado.\")\n","\n","modelo_nb = GaussianNB()\n","modelo_nb.fit(X_train.toarray(), y_train)\n","print(\"Modelo Naive Bayes treinado.\")\n","\n","modelo_arvore = DecisionTreeClassifier(random_state=42)\n","modelo_arvore.fit(X_train, y_train)\n","print(\"Modelo Árvore de Decisão treinado.\")\n","\n","modelo_rf = RandomForestClassifier(random_state=42)\n","modelo_rf.fit(X_train, y_train)\n","print(\"Modelo Random Forest treinado.\")\n","\n","# ================================\n","# 8. Avaliação\n","# ================================\n","def avaliar(y_real, y_prev, classes, nome_modelo):\n","    acuracia = accuracy_score(y_real, y_prev)\n","    matriz = confusion_matrix(y_real, y_prev)\n","\n","    print(f\"\\n--- Avaliação do modelo: {nome_modelo} ---\")\n","    print(f\"Acurácia: {acuracia * 100:.2f}%\")\n","\n","    plt.figure(figsize=(5, 4))\n","    sns.heatmap(matriz, annot=True, fmt=\"d\", cmap=\"Blues\",\n","                xticklabels=classes, yticklabels=classes)\n","    plt.title(f\"Matriz de Confusão - {nome_modelo}\")\n","    plt.ylabel(\"Valor Real\")\n","    plt.xlabel(\"Valor Predito\")\n","    plt.show()\n","\n","# Avaliando todos os modelos\n","avaliar(y_test, modelo_logistico.predict(X_test), nomes_classes, \"Regressão Logística\")\n","avaliar(y_test, modelo_nb.predict(X_test.toarray()), nomes_classes, \"Naive Bayes\")\n","avaliar(y_test, modelo_arvore.predict(X_test), nomes_classes, \"Árvore de Decisão\")\n","avaliar(y_test, modelo_rf.predict(X_test), nomes_classes, \"Random Forest\")\n","\n","# ================================\n","# 9. Salvando o melhor modelo\n","# ================================\n","melhor_modelo = modelo_arvore\n","\n","joblib.dump(melhor_modelo, \"modelo_arvore_decisao.pkl\")\n","joblib.dump(pipeline, \"pipeline_preprocessamento.pkl\")\n","\n","print(\"\\nModelo final (Árvore de Decisão) e pipeline de pré-processamento salvos"]}]}